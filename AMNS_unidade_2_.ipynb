{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO1TgPucLlDPPYM39/P3hQ+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FlavioGermanoPinheiro/unsupervised-learning/blob/main/AMNS_unidade_2_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q sentence-transformers umap-learn hdbscan scikit-learn plotly pandas matplotlib seaborn"
      ],
      "metadata": {
        "id": "bfMvE-HBhzc_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yuPqu6dchQCP"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE\n",
        "import umap.umap_ as umap\n",
        "from sklearn.cluster import KMeans\n",
        "import hdbscan\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import silhouette_score\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "import random\n",
        "\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "random.seed(SEED)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = [\n",
        " 'I swap butter for olive oil in many recipes.',\n",
        " 'Canberra is the capital of Australia.',\n",
        " 'Ottawa is the capital city of Canada.',\n",
        " 'Paris is the most populated city in France.',\n",
        " 'Tokyo is among the most populous metropolitan areas worldwide.',\n",
        " 'I prefer my coffee with no sugar and a splash of milk.',\n",
        " 'The recipe for pasta carbonara is simple.',\n",
        " 'A pinch of salt enhances sweetness in desserts.',\n",
        " 'Alignment techniques reduce harmful outputs.',\n",
        " 'Explainable AI highlights salient features for decisions.',\n",
        " 'Transformer models enable long-range language dependencies.',\n",
        " 'Black swan events stress-test portfolio resilience.',\n",
        " 'The Sahara Desert spans much of North Africa.',\n",
        " 'Inflation erodes real purchasing power of cash.',\n",
        " 'Aromatics like garlic and onion build flavor early.',\n",
        " 'Value stocks trade at lower multiples relative to fundamentals.',\n",
        " 'Quantization reduces memory with minimal accuracy loss.',\n",
        " 'Tax-loss harvesting offsets capital gains.',\n",
        " 'Investing in technology can be risky.',\n",
        " 'Fermented foods add acidity and complexity.',\n",
        " 'Marinating tofu improves texture and taste.',\n",
        " 'Vector databases power semantic search at scale.',\n",
        " 'Distillation transfers knowledge from large to small models.',\n",
        " 'The Great Barrier Reef lies off Australia’s northeast coast.',\n",
        " 'Retrieval-augmented generation grounds answers in sources.',\n",
        " 'Iceland lies on the Mid-Atlantic Ridge.',\n",
        " 'The Baltic states border the eastern Baltic Sea.',\n",
        " 'Multimodal learning aligns text with images and audio.',\n",
        " 'Risk tolerance should guide position sizing.',\n",
        " 'Time in the market beats timing the market.',\n",
        " 'Behavioral biases can derail investment plans.',\n",
        " 'Reinforcement learning fine-tunes policies from human feedback.',\n",
        " 'Edge AI runs models under strict latency constraints.',\n",
        " 'Deglazing lifts browned bits to make pan sauces.',\n",
        " 'Tempering chocolate stabilizes cocoa butter crystals.',\n",
        " 'What is the capital of France?',\n",
        " 'Johannesburg is a major city but not South Africa’s capital.',\n",
        " 'The Danube passes through multiple European capitals.',\n",
        " 'The Amazon River carries one of the largest water volumes on Earth.',\n",
        " 'A healthy emergency fund reduces forced selling.',\n",
        " 'I batch-cook grains for quick lunches.',\n",
        " 'Resting steak helps redistribute the juices.',\n",
        " 'The Atacama is one of the driest deserts on the planet.',\n",
        " 'Liquidity risk rises when trading volumes are thin.',\n",
        " 'Mount Everest is the highest peak above sea level.',\n",
        " 'Graph neural networks capture relational structure.',\n",
        " 'Sourdough starter needs regular feedings to stay active.',\n",
        " 'The stock market experienced a drop today.',\n",
        " 'Umami-rich ingredients deepen savory dishes.',\n",
        " 'Al dente pasta retains a slight bite after cooking.',\n",
        " 'Rebalancing restores target asset allocation.',\n",
        " 'Continual learning mitigates catastrophic forgetting.',\n",
        " 'Bond duration measures sensitivity to interest-rate changes.',\n",
        " 'Diffusion models synthesize high-fidelity images.',\n",
        " 'Expense ratios compound against long-term returns.',\n",
        " 'Self-supervised pretraining reduces labeled data needs.',\n",
        " 'What country contains the city of Kyoto?',\n",
        " 'Stir-frying requires high heat and constant movement.',\n",
        " 'Covered calls generate income with capped upside.',\n",
        " 'The Nile flows northward into the Mediterranean Sea.',\n",
        " 'Causal inference distinguishes correlation from effect.',\n",
        " 'Prompt engineering steers generative behavior reliably.',\n",
        " 'Few-shot prompting improves generalization on new tasks.',\n",
        " 'Growth investing prioritizes earnings expansion.',\n",
        " 'The Alps stretch across several central European countries.',\n",
        " 'The Andes form a continuous mountain range along South America.',\n",
        " 'I cook vegetarian meals on weekdays to simplify planning.',\n",
        " 'Natural language processing has advanced greatly.',\n",
        " 'Sous-vide delivers precise temperature control.',\n",
        " 'Diversification reduces idiosyncratic risk across holdings.',\n",
        " 'Sharpe ratio evaluates risk-adjusted performance.',\n",
        " 'Artificial intelligence is transforming the world.',\n",
        " 'Credit spreads widen during economic uncertainty.',\n",
        " 'Emerging markets add diversification but higher volatility.',\n",
        " 'Mise en place speeds up weeknight cooking.',\n",
        " 'The Caspian Sea is a landlocked body of water.',\n",
        " 'Evaluation with benchmarks must avoid data leakage.',\n",
        " 'Cairo sits along the Nile River delta.',\n",
        " 'Federated learning trains models without centralizing data.',\n",
        " 'Lagos is Nigeria’s largest city by population.',\n",
        " 'Dollar-cost averaging smooths entry price over time.',\n",
        " 'LoRA adapters enable efficient fine-tuning.',\n",
        " 'I keep a jar of homemade pesto for pasta.',\n",
        " 'New Delhi serves as the seat of India’s government.',\n",
        " 'I like to cook Italian dishes on Sundays.',\n",
        " 'Roasting vegetables caramelizes natural sugars.',\n",
        " 'ETFs provide broad market exposure with intraday liquidity.',\n",
        " 'Proofing time affects a bread’s crumb structure.'\n",
        "]\n",
        "N = len(sentences)\n",
        "print(f\"N = {N} sentenças\")\n"
      ],
      "metadata": {
        "id": "SEbroCHci36Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Carregar modelo BERT.\n",
        "model_name = \"bert-base-nli-mean-tokens\"  # BERT-based sentence-transformer.\n",
        "model = SentenceTransformer(model_name)\n",
        "\n",
        "# Gera embeddings.\n",
        "X = model.encode(sentences, batch_size=32, show_progress_bar=True)\n",
        "X = np.array(X)  # forma (N, dim)\n",
        "print(\"Shape dos embeddings:\", X.shape)\n"
      ],
      "metadata": {
        "id": "N4nPf0vLh2q_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n"
      ],
      "metadata": {
        "id": "BXO6mvBQh3mM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pca = PCA(n_components=0.95, random_state=SEED)  # mantém 95% da variância.\n",
        "X_pca = pca.fit_transform(X_scaled)\n",
        "print(\"Dimensionalidade após PCA (95% var):\", X_pca.shape)\n",
        "# Reduza a dimensionalidade dos embeddings para 2 componentes principais.\n",
        "pca2 = PCA(n_components=2, random_state=SEED)\n",
        "X_pca2 = pca2.fit_transform(X_scaled)\n"
      ],
      "metadata": {
        "id": "jMZHCOIeh6iT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plote os pontos resultantes com matplotlib, identificando possíveis agrupamentos. Analise qualitativamente se há separação entre textos de temas distintos.\n",
        "# Clusterização com KMeans para deixar o gráfico com um visual melhor (cores e rótulos).\n",
        "K = 5\n",
        "kmeans = KMeans(n_clusters=K, random_state=SEED)\n",
        "labels = kmeans.fit_predict(X_scaled)\n",
        "\n",
        "# Gráfico do PCA com cores e rótulos.\n",
        "plt.figure(figsize=(12,7))\n",
        "scatter = sns.scatterplot(\n",
        "    x=X_pca2[:,0], y=X_pca2[:,1],\n",
        "    hue=labels, palette=\"tab10\", s=90\n",
        ")\n",
        "\n",
        "# Adiciona texto sobre cada ponto.\n",
        "for i in range(len(X_pca2)):\n",
        "    plt.text(X_pca2[i,0] + 0.02, X_pca2[i,1] + 0.02, str(labels[i]),\n",
        "             fontsize=9, alpha=0.75)\n",
        "\n",
        "plt.title(\"PCA 2D — Embeddings agrupados por KMeans\")\n",
        "plt.xlabel(\"PC1\"); plt.ylabel(\"PC2\")\n",
        "plt.legend(title=\"Cluster\", bbox_to_anchor=(1.02,1))\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n Clusters encontrados:\")\n",
        "for c in range(K):\n",
        "   exemplos = [sentences[i] for i in range(len(labels)) if labels[i] == c][:3]  # 3 exemplos por cluster.\n",
        "   print(f\"\\nCluster {c}:\")\n",
        "   for ex in exemplos:\n",
        "      print(\" •\", ex[:80])\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "eqwLkFGQh_BK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "É possível observar a formação de clusters (0, 1, 2, 3 e 4) por temas semânticos distintos."
      ],
      "metadata": {
        "id": "n_thXxOJquyK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# t-SNE (t-distributed Stochastic Neighbor Embedding).\n",
        "\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "# Testar o ajuste de diferentes parâmetros de perplexity e learning_rate para comparar resultados.\n",
        "perplexity = 20\n",
        "learning_rate = 200\n",
        "n_iter = 1000\n",
        "random_state = SEED\n",
        "\n",
        "# Aplica t-SNE sobre os embeddings escalonados.\n",
        "tsne = TSNE(\n",
        "    n_components=2,\n",
        "    perplexity=perplexity,\n",
        "    learning_rate=learning_rate,\n",
        "    n_iter=n_iter,\n",
        "    random_state=random_state,\n",
        "    init='pca',\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "X_tsne = tsne.fit_transform(X_scaled)\n",
        "print(\"Shape após t-SNE:\", X_tsne.shape)\n",
        "\n",
        "# Visualização dos resultados.\n",
        "plt.figure(figsize=(12,7))\n",
        "scatter = sns.scatterplot(\n",
        "    x=X_tsne[:,0], y=X_tsne[:,1],\n",
        "    hue=labels, palette=\"tab10\", s=90\n",
        ")\n",
        "\n",
        "# Rótulos de cluster.\n",
        "for i in range(len(X_tsne)):\n",
        "    plt.text(X_tsne[i,0] + 0.5, X_tsne[i,1] + 0.5, str(labels[i]),\n",
        "             fontsize=9, alpha=0.7)\n",
        "\n",
        "plt.title(f\"t-SNE (perplexity={perplexity}, lr={learning_rate}) — estrutura local dos embeddings\")\n",
        "plt.xlabel(\"Dim 1\"); plt.ylabel(\"Dim 2\")\n",
        "plt.legend(title=\"Cluster\", bbox_to_anchor=(1.02, 1))\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "0UzRpk3cuQEf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Os clusters ficaram melhores ajustados entre 20 e 30 do parâmetro perplexity e com relação a taxa de aprendizado (learning_rate), obteve um melhor ajuste no valor de 200. Pode-se observar também os agrupamentos de clusters, ou seja,que apresentou boa coerência semântica dos embeddings."
      ],
      "metadata": {
        "id": "dV-udeCXwlMS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# UMAP (Uniform Manifold Approximation and Projection).\n",
        "\n",
        "import umap.umap_ as umap\n",
        "\n",
        "# Experimente variar n_neighbors e min_dist para observar mudanças na distribuição dos clusters.\n",
        "n_neighbors = 15\n",
        "min_dist = 0.1\n",
        "n_components = 2\n",
        "metric = 'euclidean'\n",
        "\n",
        "# Ajuste do modelo UMAP.\n",
        "umap_model = umap.UMAP(\n",
        "    n_neighbors=n_neighbors,\n",
        "    min_dist=min_dist,\n",
        "    n_components=n_components,\n",
        "    metric=metric,\n",
        "    random_state=SEED\n",
        ")\n",
        "\n",
        "X_umap = umap_model.fit_transform(X_scaled)\n",
        "print(\"Shape após UMAP:\", X_umap.shape)\n",
        "\n",
        "# Visualização dos clusters.\n",
        "plt.figure(figsize=(12,7))\n",
        "scatter = sns.scatterplot(\n",
        "    x=X_umap[:,0], y=X_umap[:,1],\n",
        "    hue=labels, palette=\"tab10\", s=90\n",
        ")\n",
        "\n",
        "# Adiciona rótulos de cluster sobre os pontos.\n",
        "for i in range(len(X_umap)):\n",
        "    plt.text(X_umap[i,0] + 0.1, X_umap[i,1] + 0.1, str(labels[i]),\n",
        "             fontsize=9, alpha=0.75)\n",
        "\n",
        "plt.title(f\"UMAP 2D — n_neighbors={n_neighbors}, min_dist={min_dist}\")\n",
        "plt.xlabel(\"Dim 1\"); plt.ylabel(\"Dim 2\")\n",
        "plt.legend(title=\"Cluster\", bbox_to_anchor=(1.02,1))\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "fVl2EtXi0iZk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "É possível observar que quanto menor o valor do número de vizinhos (n_neighbors) mais coesos ficam os clusters. O valor padrão de 15 fornece uma boa visualização dos clusters. Com relação a (min_dist) distância mínima, o valor de até 0.1 proporciona clusters mais compactos e acima disso clusters mais espalhados, separando mais os grupos."
      ],
      "metadata": {
        "id": "PLQqZj3s2xC_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A comparação visual com os resultados do PCA e t-SNE, mostram que o melhor agrupamento (mais equlibrado) ficou com o UMAP sendo o pior resultado para o PCA o qual apresentou clusters mais espaçados que os demais."
      ],
      "metadata": {
        "id": "M-ZMs-gA6zvO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Classificação.\n",
        "\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "\n",
        "cluster_nomes = {\n",
        "    0: \"Finanças\",\n",
        "    1: \"Economia\",\n",
        "    2: \"Geografia\",\n",
        "    3: \"Inteligência Artificial e Machine Learning\",\n",
        "    4: \"Culinária\"\n",
        "}\n",
        "\n",
        "# Calcula os centróides dos clusters existentes.\n",
        "cluster_centroids = []\n",
        "for c in range(K):\n",
        "    centroid = X_scaled[labels == c].mean(axis=0)\n",
        "    cluster_centroids.append(centroid)\n",
        "cluster_centroids = np.vstack(cluster_centroids)\n",
        "\n",
        "# Função para gerar o embedding do texto.\n",
        "def classificar_texto(texto: str):\n",
        "\n",
        "    emb = model.encode([texto])\n",
        "    emb_scaled = scaler.transform(emb)\n",
        "\n",
        "# Calcula a similaridade entre embedding e centróide.\n",
        "    sims = cosine_similarity(emb_scaled, cluster_centroids)[0]\n",
        "    cluster_pred = np.argmax(sims)\n",
        "\n",
        "    nome_cluster = cluster_nomes.get(cluster_pred, f\"Cluster {cluster_pred}\")\n",
        "    print(f\"\\nTexto: {texto}\")\n",
        "    print(f\"→ Cluster mais próximo: {cluster_pred} ({nome_cluster})\")\n",
        "    print(f\"Similaridades: {np.round(sims, 3)}\")\n",
        "    return cluster_pred, nome_cluster\n"
      ],
      "metadata": {
        "id": "qmAgEXpb8YKt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testes de exemplo.\n",
        "testes = [\n",
        " \"Bond duration measures sensitivity to interest-rate changes.\",\n",
        " \"Diffusion models synthesize high-fidelity images.\",\n",
        " \"Expense ratios compound against long-term returns.\",\n",
        " \"Self-supervised pretraining reduces labeled data needs.\",\n",
        " \"What country contains the city of Kyoto?\",\n",
        " \"Stir-frying requires high heat and constant movement.\"\n",
        "]\n",
        "\n",
        "for texto in testes:\n",
        "    classificar_texto(texto)\n"
      ],
      "metadata": {
        "id": "-0qAxQor-xNm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pode-se observar que com relação a parte \"Similaridades:\" os valores quanto mais próximos de 1.0 (idêntico) mais correlaciona o texto a determinado cluster (mostra o grau de similaridade coseno entre o texto e cada centróide de cluster)."
      ],
      "metadata": {
        "id": "xrExnqsoCLa5"
      }
    }
  ]
}